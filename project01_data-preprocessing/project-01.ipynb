{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.base import clone\n",
    "#from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expriment objective:*\n",
    "To determine credit card level by account information for credit card holders. \n",
    "*Ethic Considerations:*\n",
    "Gender is included in this dataset. Though as we can see, it does not contribute too significantly to classification, at least in forest classification, it *is* listed as a binary. \n",
    "\n",
    "This data is taken from Kaggle, and prior, was pulled from a website for datasets. Thus, this is not proprietary nor does it contain private data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.999910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>818770008</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.999940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713982108</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769911858</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.999870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709106358</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>772366833</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1851</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>15476</td>\n",
       "      <td>117</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>710638233</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>2186</td>\n",
       "      <td>2091.0</td>\n",
       "      <td>0.804</td>\n",
       "      <td>8764</td>\n",
       "      <td>69</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.995270</td>\n",
       "      <td>0.004729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>716506083</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0.819</td>\n",
       "      <td>10291</td>\n",
       "      <td>60</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.997880</td>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>717406983</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0.535</td>\n",
       "      <td>8395</td>\n",
       "      <td>62</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>0.003294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>714337233</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Silver</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>10388.0</td>\n",
       "      <td>1961</td>\n",
       "      <td>8427.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>10294</td>\n",
       "      <td>61</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.996620</td>\n",
       "      <td>0.003377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0      768805383  Existing Customer            45      M                3   \n",
       "1      818770008  Existing Customer            49      F                5   \n",
       "2      713982108  Existing Customer            51      M                3   \n",
       "3      769911858  Existing Customer            40      F                4   \n",
       "4      709106358  Existing Customer            40      M                3   \n",
       "...          ...                ...           ...    ...              ...   \n",
       "10122  772366833  Existing Customer            50      M                2   \n",
       "10123  710638233  Attrited Customer            41      M                2   \n",
       "10124  716506083  Attrited Customer            44      F                1   \n",
       "10125  717406983  Attrited Customer            30      M                2   \n",
       "10126  714337233  Attrited Customer            43      F                2   \n",
       "\n",
       "      Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0         High School        Married     $60K - $80K          Blue   \n",
       "1            Graduate         Single  Less than $40K          Blue   \n",
       "2            Graduate        Married    $80K - $120K          Blue   \n",
       "3         High School        Unknown  Less than $40K          Blue   \n",
       "4          Uneducated        Married     $60K - $80K          Blue   \n",
       "...               ...            ...             ...           ...   \n",
       "10122        Graduate         Single     $40K - $60K          Blue   \n",
       "10123         Unknown       Divorced     $40K - $60K          Blue   \n",
       "10124     High School        Married  Less than $40K          Blue   \n",
       "10125        Graduate        Unknown     $40K - $60K          Blue   \n",
       "10126        Graduate        Married  Less than $40K        Silver   \n",
       "\n",
       "       Months_on_book  ...  Credit_Limit  Total_Revolving_Bal  \\\n",
       "0                  39  ...       12691.0                  777   \n",
       "1                  44  ...        8256.0                  864   \n",
       "2                  36  ...        3418.0                    0   \n",
       "3                  34  ...        3313.0                 2517   \n",
       "4                  21  ...        4716.0                    0   \n",
       "...               ...  ...           ...                  ...   \n",
       "10122              40  ...        4003.0                 1851   \n",
       "10123              25  ...        4277.0                 2186   \n",
       "10124              36  ...        5409.0                    0   \n",
       "10125              36  ...        5281.0                    0   \n",
       "10126              25  ...       10388.0                 1961   \n",
       "\n",
       "       Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "0              11914.0                 1.335             1144              42   \n",
       "1               7392.0                 1.541             1291              33   \n",
       "2               3418.0                 2.594             1887              20   \n",
       "3                796.0                 1.405             1171              20   \n",
       "4               4716.0                 2.175              816              28   \n",
       "...                ...                   ...              ...             ...   \n",
       "10122           2152.0                 0.703            15476             117   \n",
       "10123           2091.0                 0.804             8764              69   \n",
       "10124           5409.0                 0.819            10291              60   \n",
       "10125           5281.0                 0.535             8395              62   \n",
       "10126           8427.0                 0.703            10294              61   \n",
       "\n",
       "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \\\n",
       "0                    1.625                  0.061   \n",
       "1                    3.714                  0.105   \n",
       "2                    2.333                  0.000   \n",
       "3                    2.333                  0.760   \n",
       "4                    2.500                  0.000   \n",
       "...                    ...                    ...   \n",
       "10122                0.857                  0.462   \n",
       "10123                0.683                  0.511   \n",
       "10124                0.818                  0.000   \n",
       "10125                0.722                  0.000   \n",
       "10126                0.649                  0.189   \n",
       "\n",
       "       Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  \\\n",
       "0                                               0.000093                                                                                    \n",
       "1                                               0.000057                                                                                    \n",
       "2                                               0.000021                                                                                    \n",
       "3                                               0.000134                                                                                    \n",
       "4                                               0.000022                                                                                    \n",
       "...                                                  ...                                                                                    \n",
       "10122                                           0.000191                                                                                    \n",
       "10123                                           0.995270                                                                                    \n",
       "10124                                           0.997880                                                                                    \n",
       "10125                                           0.996710                                                                                    \n",
       "10126                                           0.996620                                                                                    \n",
       "\n",
       "       Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  \n",
       "0                                               0.999910                                                                                   \n",
       "1                                               0.999940                                                                                   \n",
       "2                                               0.999980                                                                                   \n",
       "3                                               0.999870                                                                                   \n",
       "4                                               0.999980                                                                                   \n",
       "...                                                  ...                                                                                   \n",
       "10122                                           0.999810                                                                                   \n",
       "10123                                           0.004729                                                                                   \n",
       "10124                                           0.002118                                                                                   \n",
       "10125                                           0.003294                                                                                   \n",
       "10126                                           0.003377                                                                                   \n",
       "\n",
       "[10127 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Data Collection\n",
    "\n",
    "#Data From : https://www.kaggle.com/sakshigoyal7/credit-card-customers/download\n",
    "        #info on the dataset : https://www.kaggle.com/sakshigoyal7/credit-card-customers\n",
    "\n",
    "credit = pd.read_csv(\"BankChurners.csv\")\n",
    "\n",
    "credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Collection Discussion*\n",
    "As stated from the expirimental objective section, this data was downloaded from kaggle in the form of a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data Preprocessing\n",
    "\n",
    "credit = credit.drop(\"CLIENTNUM\", axis=1)\n",
    "credit_mapping = {'Blue': 1,\n",
    "                  'Silver': 2,\n",
    "                  'Gold': 3, \n",
    "                  'Platinum': 4}\n",
    "credit['Card_Category'] = credit['Card_Category'].map(credit_mapping)\n",
    "credit = pd.get_dummies(credit, drop_first=True)\n",
    "\n",
    "credit_all = credit\n",
    "\n",
    "y = credit['Card_Category']\n",
    "X = credit.drop(\"Card_Category\", axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, \n",
    "                     test_size=0.3, \n",
    "                     random_state=0, \n",
    "                     stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Preprocessing*\n",
    "As there are four classes, I chose to manually encode the class lables to numbers - as the classes are indeed ordinal, I thought this was a good was to encode them.\n",
    "\n",
    "I have also dropped CLIENTNUM, as it is essentially an index, and unnecessary to examine. \n",
    "There were no other missing or obselete variables, thus I initiated panda's get_dummies to encode the categorical variables present such as Gender and Marital_status.\n",
    "\n",
    "I have chose to scale the data by StandardScaler as the three models I chose need a scaled dataset to process. \n",
    "\n",
    "For feature selection, please see \"#Model Comparison with chosen features\" section. I have used a random forrest to determine feature importance, and select features that had an importance of over 0.03 - resulting in 12 features. I have chosen to compare logistic regression, SVM, and KNN both with all of the features, and with only the selected features over the random forest threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "10122    1\n",
       "10123    1\n",
       "10124    1\n",
       "10125    1\n",
       "10126    2\n",
       "Name: Card_Category, Length: 10127, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy LR all features: 0.9659988713318285\n",
      "Test accuracy LR all features: 0.9647910496873972\n",
      "\n",
      "Training accuracy SVM all features: 0.9688205417607223\n",
      "Test accuracy SVM all features: 0.9657782165185916\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8941c88e7e28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m##KNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m knn = KNeighborsClassifier(n_neighbors=5, \n\u001b[0m\u001b[1;32m     21\u001b[0m                            \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                            metric='minkowski')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "##Model Comparison with all features\n",
    "\n",
    "#Logistic Regression\n",
    "lr = LogisticRegression(penalty='l1', C=1.0, solver='liblinear', multi_class='ovr', max_iter = 2000)\n",
    "lr.fit(X_train_std, y_train)\n",
    "print('Training accuracy LR all features:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy LR all features:', lr.score(X_test_std, y_test))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#Suport Vector Machine \n",
    "svm = SVC(kernel='linear', C=1.0, random_state=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "print('Training accuracy SVM all features:', svm.score(X_train_std, y_train))\n",
    "print('Test accuracy SVM all features:',  svm.score(X_test_std, y_test))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "##KNN \n",
    "knn = KNeighborsClassifier(n_neighbors=5, \n",
    "                           p=2, \n",
    "                           metric='minkowski')\n",
    "knn.fit(X_train_std, y_train)\n",
    "knn.score(X_train_std, y_train)\n",
    "print('Training accuracy KNN all features:', knn.score(X_train_std, y_train))\n",
    "print('Test accuracy KNN all features:', knn.score(X_test_std, y_test))\n",
    "print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) Credit_Limit                   0.190710\n",
      " 2) Avg_Open_To_Buy                0.177840\n",
      " 3) Avg_Utilization_Ratio          0.053073\n",
      " 4) Income_Category_Less than $40K 0.052178\n",
      " 5) Total_Trans_Amt                0.050517\n",
      " 6) Total_Trans_Ct                 0.040455\n",
      " 7) Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1 0.035818\n",
      " 8) Total_Ct_Chng_Q4_Q1            0.034511\n",
      " 9) Total_Revolving_Bal            0.034299\n",
      "10) Total_Amt_Chng_Q4_Q1           0.032922\n",
      "11) Income_Category_$40K - $60K    0.032184\n",
      "12) Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2 0.031316\n",
      "13) Dependent_count                0.029420\n",
      "14) Months_on_book                 0.027534\n",
      "15) Income_Category_$60K - $80K    0.025961\n",
      "16) Gender_M                       0.018836\n",
      "17) Card_Category                  0.017743\n",
      "18) Total_Relationship_Count       0.017440\n",
      "19) Income_Category_Unknown        0.015894\n",
      "20) Contacts_Count_12_mon          0.013957\n",
      "21) Months_Inactive_12_mon         0.013524\n",
      "22) Income_Category_$80K - $120K   0.012294\n",
      "23) Education_Level_Graduate       0.005920\n",
      "24) Marital_Status_Single          0.005598\n",
      "25) Marital_Status_Married         0.005199\n",
      "26) Education_Level_Unknown        0.005030\n",
      "27) Education_Level_High School    0.004526\n",
      "28) Education_Level_Uneducated     0.004352\n",
      "29) Marital_Status_Unknown         0.003270\n",
      "30) Education_Level_Post-Graduate  0.003258\n",
      "31) Attrition_Flag_Existing Customer 0.002478\n",
      "32) Education_Level_Doctorate      0.001944\n",
      "\n",
      "Number of features that meet threshold criterion of 0.03: 12\n",
      "['Credit_Limit', 'Avg_Open_To_Buy', 'Avg_Utilization_Ratio', 'Income_Category_Less than $40K', 'Total_Trans_Amt', 'Total_Trans_Ct', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Total_Ct_Chng_Q4_Q1', 'Total_Revolving_Bal', 'Total_Amt_Chng_Q4_Q1', 'Income_Category_$40K - $60K', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2']\n",
      "\n",
      "Training accuracy LR paired features: 0.9503386004514672\n",
      "Test accuracy LR paired features: 0.9460348798947023\n",
      "\n",
      "Training accuracy SVM paired features: 0.9533013544018059\n",
      "Test accuracy SVM paired features: 0.9473511023362948\n",
      "\n",
      "Training accuracy KNN paired features: 0.9585214446952596\n",
      "Test accuracy KNN paired features: 0.935176044751563\n"
     ]
    }
   ],
   "source": [
    "##Model Comparison with chosen features\n",
    "\n",
    "\n",
    "#Random forest to asses feature importance \n",
    "feat_labels = credit.columns[1:]\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500,\n",
    "                                random_state=0)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "######Paired-down features\n",
    "\n",
    "sfm = SelectFromModel(forest, threshold=0.03, prefit=True)\n",
    "X_selected = sfm.transform(X_train)\n",
    "\n",
    "print(\"\")\n",
    "print('Number of features that meet threshold criterion of 0.03:', \n",
    "      X_selected.shape[1])\n",
    "feat_list_subset = []\n",
    "for f in range(X_selected.shape[1]):\n",
    "    feat_list_subset.append(feat_labels[indices[f]])\n",
    "credit2 = credit[feat_list_subset]\n",
    "\n",
    "print(feat_list_subset)\n",
    "\n",
    "X = credit2.iloc[:, :]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, \n",
    "                     test_size=0.3, \n",
    "                     random_state=0, \n",
    "                     stratify=y)\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "\n",
    "\n",
    "#LR with chosen features\n",
    "lr = LogisticRegression(penalty='l1', C=1.0, solver='liblinear', multi_class='ovr', max_iter = 2000)\n",
    "lr.fit(X_train_std, y_train)\n",
    "print(\"\")\n",
    "print('Training accuracy LR paired features:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy LR paired features:', lr.score(X_test_std, y_test))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#SVM with chose features\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "print('Training accuracy SVM paired features:', svm.score(X_train_std, y_train))\n",
    "print('Test accuracy SVM paired features:', svm.score(X_test_std, y_test))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "##KNN with chosen features\n",
    "knn = KNeighborsClassifier(n_neighbors=5, \n",
    "                           p=2, \n",
    "                           metric='minkowski')\n",
    "knn.fit(X_train_std, y_train)\n",
    "knn.score(X_train_std, y_train)\n",
    "print('Training accuracy KNN paired features:', knn.score(X_train_std, y_train))\n",
    "print('Test accuracy KNN paired features:', knn.score(X_test_std, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model Comparison*\n",
    "\n",
    "Training accuracy LR all features: 0.9659988713318285\n",
    "Test accuracy LR all features: 0.9647910496873972\n",
    "\n",
    "Training accuracy SVM all features: 0.9688205417607223\n",
    "Test accuracy SVM all features: 0.9657782165185916\n",
    "\n",
    "Training accuracy KNN all features: 0.9442720090293454\n",
    "Test accuracy KNN all features: 0.9361632115827575\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Training accuracy LR paired features: 0.9503386004514672\n",
    "Test accuracy LR paired features: 0.9460348798947023\n",
    "\n",
    "Training accuracy SVM paired features: 0.9533013544018059\n",
    "Test accuracy SVM paired features: 0.9473511023362948\n",
    "\n",
    "Training accuracy KNN paired features: 0.9585214446952596\n",
    "Test accuracy KNN paired features: 0.935176044751563\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Between the models, Support Vector Machine with all of the features functioned the best. Too, between the feature-scaled models, SVM was most accurate as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Experiment Summary*\n",
    "The data for this project was collected from Kaggle's project Bank Churners. To preprocess the data, I had to map class lables to oridinal values, and encode the rest of the categorical variables via Panda's get_dummies. The data was scaled via StandardScaler, and did feature selection via random forest feature importances. Overall, the SVM model performed best the all-feature data, and KNN performed best with the paired-feature data. \n",
    "\n",
    "Overall, it was very interesting to see which feature impacted the classification of credit card level most- including transaction amount and credit limit which make sense, but also features such as Avg open to buy credit line, which, at face value, doesn't seem like it would impact the classification as much as it does (second highest impact). The SVM model was able to pretty well classify the data into card categories, as were the other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
